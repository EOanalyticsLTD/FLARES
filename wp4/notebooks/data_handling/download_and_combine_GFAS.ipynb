{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ed32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "\n",
    "if os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))) not in sys.path:\n",
    "    sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "\n",
    "from ecmwfapi import ECMWFDataServer\n",
    "import xarray as xr\n",
    "import calendar\n",
    "    \n",
    "from wp4.constants import DATA_DIR_GFAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13313f",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "For this script to work the ECMWF Api needs to be set up properly. For more information on how to sign up and use this API see: \n",
    "\n",
    "\n",
    "\n",
    "### Efficient requests\n",
    "\n",
    "Data retrieval is not designed to be instant. A larger request can take hours and even days to complete.\n",
    "\n",
    "To retrieve data efficiently (and get your data quicker!) you should retrieve all the data you need from one tape, then from the next tape, and so on. For GFAS, this means retrieving all the data you need for one month, then for the next month, and so on.  \n",
    "\n",
    "https://confluence.ecmwf.int/display/WEBAPI/Retrieval+efficiency\n",
    "\n",
    "https://confluence.ecmwf.int/display/UDOC/Retrieve#Retrieve-Retrievalefficiency\n",
    "\n",
    "\n",
    "### Parameters\n",
    "\n",
    "Some of the most relevant parameters for the requests:\n",
    "\n",
    "##### param\n",
    "\n",
    "*80.210*  : Wildfire flux of Carbon Dioxide\\\n",
    "*81.210*  : Wildfire flux of Carbon Monoxide\\\n",
    "*82.210*  : Wildfire flux of Methane\\\n",
    "*85.210*  : Wildfire flux of Nitrogen Oxides NOx\\\n",
    "*87.210*  : Wildfire flux of Particulate Matter PM2.5\\\n",
    "*88.210*  : Wildfire flux of Total Particulate Matter\\\n",
    "*102.210* : Wildfire flux of Sulfur Dioxide\\\n",
    "*99.210*  : Wildfire radiative power\n",
    "\n",
    "full list here: https://confluence.ecmwf.int/display/CKB/CAMS%3A+Global+Fire+Assimilation+System+%28GFAS%29+data+documentation\n",
    "\n",
    "##### type\n",
    "\n",
    "*gsd* : gridded satellite data (hourly) - Only available for fire radiative power (FRP)\\\n",
    "*ga* : gridded average (daily average)\n",
    "\n",
    "check the data catalogue here to see what is available for download: https://apps.ecmwf.int/archive-catalogue/?type=gsd&class=mc&stream=gfas&expver=0001\n",
    "\n",
    "##### instrument\n",
    "\n",
    "*389*: MODIS\n",
    "\n",
    "##### ident\n",
    "\n",
    "*784* : Aqua\\\n",
    "*783* : Terra\n",
    "\n",
    "##### format\n",
    "\n",
    "If not format is specified the data will be downloaded as a grib file, set *netcdf* for the format paramater to have the data converted to a netcdf file on the server before downloading.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba9288",
   "metadata": {},
   "source": [
    "## Step 1. Create/check the directories to store the data\n",
    "\n",
    "As only the FRP data is available on an hourly basis we cannot acquire all the data for each month using a single server request. Therefore the downloading will be split up into two different request loops, one loop requesting the FRP data for each month, the other requesting the wildfire fluxes that are of interest for the Flares product. For each of the loops a different directory will be used for storing the downloaded data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84627dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{DATA_DIR_GFAS}/frp/'):\n",
    "    os.makedirs(f'{DATA_DIR_GFAS}/frp/')\n",
    "    \n",
    "if not os.path.exists(f'{DATA_DIR_GFAS}/flux/'):\n",
    "    os.makedirs(f'{DATA_DIR_GFAS}/flux/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d0f2a",
   "metadata": {},
   "source": [
    "## Step 2. Run first for loop, downloading the hourly FRP data for each month, starting from 2015. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396176b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the server\n",
    "server = ECMWFDataServer()\n",
    "\n",
    "for year in [2015, 2016, 2017, 2018, 2019, 2020, 2021]:\n",
    "    for month in ['01','02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']:     \n",
    "        \n",
    "        # get the number of days in the month\n",
    "        days_in_month = calendar.monthrange(year, int(month))[1]\n",
    "        \n",
    "        # Target location to store the downloaded data \n",
    "        output_loc = f'{DATA_DIR_GFAS}/frp/{year}_{month}.nc'\n",
    "        \n",
    "        \n",
    "        # If the file already exists, continue with next iteration\n",
    "        if os.path.exists(output_loc):\n",
    "            print(f'SKIPPED: {year}_{month}.nc')\n",
    "            continue\n",
    "        else:\n",
    "            print(f'STARTING DOWNLOAD REQUEST FOR: {year}_{month}.nc')\n",
    "        \n",
    "        # Set request parameters and send the request\n",
    "        server.retrieve({\n",
    "            \"class\": \"mc\",\n",
    "            \"dataset\": \"cams_gfas\",\n",
    "            \"date\": f\"{year}-{month}-01/to/{year}-{month}-{days_in_month}\",\n",
    "            \"expver\": \"0001\",\n",
    "            \"levtype\": \"sfc\",\n",
    "            \"param\": \"99.210\",\n",
    "            \"step\": \"0-24\",\n",
    "            \"stream\": \"gfas\",\n",
    "            \"time\": \"0/1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17/18/19/20/21/22/23\",\n",
    "            \"type\": \"gsd\",\n",
    "            \"ident\": \"784/783\",\n",
    "            \"instrument\": \"389\",\n",
    "            \"area\":\"55.65/-11.35/51.35/-5.25\",\n",
    "            \"grid\":\"0.1/0.1\",\n",
    "            \"format\": \"netcdf\",\n",
    "            \"target\": output_loc,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61cc177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the server\n",
    "server = ECMWFDataServer()\n",
    "\n",
    "for year in [2015, 2016, 2017, 2018, 2019, 2020, 2021]:\n",
    "    for month in ['01','02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']:\n",
    "        \n",
    "        # get the number of days in the month\n",
    "        days_in_month = calendar.monthrange(year, int(month))[1]\n",
    "        \n",
    "        # Target location to store the downloaded data \n",
    "        output_loc = f'{DATA_DIR_GFAS}/flux/{year}_{month}.nc'\n",
    "        \n",
    "        # If the file already exists, continue with next iteration\n",
    "        if os.path.exists(output_loc):\n",
    "            print(f'SKIPPED: {year}_{month}.nc')\n",
    "            continue\n",
    "        else:\n",
    "            print(f'STARTING DOWNLOAD REQUEST FOR: {year}_{month}.nc')\n",
    "        \n",
    "        # Set request parameters and send the request\n",
    "        server.retrieve({\n",
    "            \"class\": \"mc\",\n",
    "            \"dataset\": \"cams_gfas\",\n",
    "            \"date\": f\"{year}-{month}-01/to/{year}-{month}-{days_in_month}\",\n",
    "            \"expver\": \"0001\",\n",
    "            \"levtype\": \"sfc\",\n",
    "            \"param\": \"80.210/81.210/82.210/85.210/87.210/88.210/102.210\",\n",
    "            \"step\": \"0-24\",\n",
    "            \"stream\": \"gfas\",\n",
    "            \"target\": output_loc,\n",
    "            \"format\": \"netcdf\",\n",
    "            \"time\": \"00\",\n",
    "            \"type\": \"ga\",\n",
    "            \"area\":\"55.65/-11.35/51.35/-5.25\",\n",
    "            \"grid\":\"0.1/0.1\",\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc808ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the filenames ending on nc in the download directory \n",
    "monthly_frp_files = glob.glob(f'{DATA_DIR_GFAS}/frp/*.nc')\n",
    "\n",
    "# open each nc file using xarray\n",
    "monthly_frp_datasets = [xr.open_dataset(x) for x in monthly_frp_files]\n",
    "\n",
    "# combine the data along the time dimension using the xarray combine_nested function \n",
    "ds = xr.combine_nested(monthly_frp_datasets , concat_dim='time', combine_attrs='drop_conflicts')\n",
    "\n",
    "# sort the data based on date\n",
    "sorted_ds = ds.sortby('time')\n",
    "\n",
    "# save as a single netcdf file\n",
    "sorted_ds.to_netcdf(f'{DATA_DIR_GFAS}/frp.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the filenames ending on nc in the download directory \n",
    "monthly_flux_files = glob.glob(f'{DATA_DIR_GFAS}/flux/*.nc')\n",
    "\n",
    "# open each nc file using xarray\n",
    "monthly_flux_files = [xr.open_dataset(x) for x in monthly_flux_files]\n",
    "\n",
    "# combine the data along the time dimension using the xarray combine_nested function \n",
    "ds = xr.combine_nested(monthly_flux_files , concat_dim='time', combine_attrs='drop_conflicts')\n",
    "\n",
    "# sort the data based on date\n",
    "sorted_ds = ds.sortby('time')\n",
    "\n",
    "# save as a single netcdf file\n",
    "sorted_ds.to_netcdf(f'{DATA_DIR_GFAS}/wildfire_flux.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
