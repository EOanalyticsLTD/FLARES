{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fcbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# adds the package path to the Python path to make sure all the local imports work fine \n",
    "if os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))) not in sys.path:\n",
    "    sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "\n",
    "# local imports \n",
    "from wp4.constants import POLLUTANTS, DATA_DIR_CAMS_AN, DATA_DIR_CAMS_RE, DATA_DIR_GFAS, DATA_DIR_PLOTS, DB_HOST, DB_NAME, DB_USER, DB_PASS, ADS_URL, ADS_KEY, EXTENTS \n",
    "from wp4.baseline.spatial import get_spatial_baseline\n",
    "from wp4.baseline.temporal import get_temporal_baseline\n",
    "from wp4.processing.ground_stations import get_closest_ground_station_historical_data\n",
    "\n",
    "# import remaining packages needed for the script\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "import cdsapi\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Filters out a warning that pops up when calling the ADS api when using the credentials as parameters\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request is being made to host \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1048f5a5",
   "metadata": {},
   "source": [
    "## Set the search/plotting criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc23736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time window to select fire events from the database from\n",
    "time_window = {\n",
    "    'start':datetime(year=2018, month=5, day=1, hour = 0),\n",
    "    'end':datetime(year=2018, month=6, day=30, hour = 23)\n",
    "}\n",
    "\n",
    "# The number of days for which to include data in the graphs, so for 7 the graph will start at 7 days before the event\n",
    "# and end 7 days after\n",
    "\n",
    "DAYS = 7\n",
    "\n",
    "# Select which datasets you want to include in the graph\n",
    "FORECAST = False  # If you want to include the European Air Quality Forecast in the graph set this to True\n",
    "FC_LEADTIME = 24  # How many hours into the future to select from the forecast. 24 hours gives a smooth line\n",
    "ANALYSIS = False  # If you want to include the European Air Quality NRT Analysis in the graph set this to True\n",
    "REANALYSIS = True  # If you want to include the European Air Quality Renalysis in the graph set this to True (2018 only) \n",
    "GROUND_STATIONS = False  # if you don't want to include the data from the ground stations, set this to False\n",
    "FRP = True\n",
    "PM10_WILDFIRES = False\n",
    "TEMPORAL_BASELINE = False\n",
    "SPATIAL_BASELINE_AN = False\n",
    "SPATIAL_BASELINE_RE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815d502",
   "metadata": {},
   "source": [
    "## Load the fire events from the Flares2 database for the given time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd159983",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=DB_NAME, user=DB_USER, password=DB_PASS, host=DB_HOST)\n",
    "cur = conn.cursor()\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT id, datetime, ST_X(geometry), ST_Y(geometry), source, location, reference, type, info, frp\n",
    "    FROM public.all_fire_events\n",
    "    WHERE (reference = 'Aqua' OR reference = 'Terra') AND \"frp\" IS NOT NULL    \n",
    "    AND (datetime >= '{time_window['start'].strftime('%Y-%m-%d')}' AND datetime <= '{time_window['end'].strftime('%Y-%m-%d')}');\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "df_fire_events = pd.read_sql_query(query,con=conn).rename(columns = {'st_x':'longitude', 'st_y':'latitude'})\n",
    "\n",
    "conn.close()\n",
    "\n",
    "if len(df_fire_events) == 0:\n",
    "    print('No fire events found matching your search parameters')\n",
    "else:\n",
    "    print(f'Fire events loaded from database: {len(df_fire_events)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd19048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Forecast & Analysis for the fire event\n",
    "\n",
    "def create_plot(fig, col, row, name_pollutant, df_fire_event, df_temporal=None,\n",
    "                df_spatial=None, second_y=False, file_name=None, show_legend=False):\n",
    "    \n",
    "    colors = {\n",
    "        'temporal_median':'#38b000',\n",
    "        'temporal_range':'#b5e48c',\n",
    "        'spatial_median':'#5e60ce',\n",
    "        'spatial_range':'#bde0fe',\n",
    "        'fire_event':'#e31a1c',\n",
    "    }\n",
    "    \n",
    "    if df_temporal is not None:\n",
    "                      \n",
    "        fig.add_trace(go.Scatter(  # add the baseline values\n",
    "                    x=df_temporal['time'],\n",
    "                    y=df_temporal['temporal_baseline_lower_quartile'].rolling(window=3, min_periods=1).mean(),\n",
    "                    mode='lines', \n",
    "                    name='25th percentile (Temporal)',\n",
    "                    line={'color': colors['temporal_range']}),col=col, row=row\n",
    "                )\n",
    "\n",
    "        fig.add_trace(go.Scatter(  # add the baseline values\n",
    "                    x=df_temporal['time'],\n",
    "                    y=df_temporal['temporal_baseline_upper_quartile'].rolling(window=3, min_periods=1).mean(),\n",
    "                    fill='tonexty', # fill area between trace0 and trace1\n",
    "                    mode='lines',\n",
    "                    name='75th percentile (Temporal)',\n",
    "                    line={'color': colors['temporal_range']}),col=col, row=row\n",
    "                )\n",
    "\n",
    "        fig.add_trace(go.Scatter(  # add the baseline values\n",
    "                    x=df_temporal['time'],\n",
    "                    y=df_temporal['temporal_baseline_median'].rolling(window=3, min_periods=1).mean(),\n",
    "                    mode='lines',\n",
    "                    name='Median (Temporal)',\n",
    "                    line={'color': colors['temporal_median']}),col=col, row=row\n",
    "                )\n",
    "    \n",
    "    if df_spatial is not None:\n",
    "        fig.add_trace(go.Scatter(  # add the baseline values\n",
    "                    x=df_spatial['time'],\n",
    "                    y=df_spatial['spatial_baseline_lower_quartile'].rolling(window=3, min_periods=1).mean(),\n",
    "                    mode='lines',\n",
    "                    legendgroup=f\"group_baseline\",\n",
    "                    name='25th percentile (Spatial)',\n",
    "                    line={'color': colors['spatial_range']}),col=col, row=row\n",
    "                )\n",
    "\n",
    "        fig.add_trace(go.Scatter(  # add the baseline values\n",
    "                    x=df_spatial['time'],\n",
    "                    y=df_spatial['spatial_baseline_upper_quartile'].rolling(window=3, min_periods=1).mean(),\n",
    "                    fill='tonexty', # fill area between trace0 and trace1\n",
    "                    mode='lines',\n",
    "                    legendgroup=f\"group_baseline\",\n",
    "                    name='75th percentile (Spatial)',\n",
    "                    line={'color': colors['spatial_range']}),col=col, row=row\n",
    "                )\n",
    "\n",
    "        fig.add_trace(go.Scatter(  # add the baseline values\n",
    "                    x=df_spatial['time'],\n",
    "                    y=df_spatial['spatial_baseline_median'].rolling(window=3, min_periods=1).mean(),\n",
    "                    mode='lines',\n",
    "                    name='Median (Spatial)',\n",
    "                    legendgroup=f\"group_baseline\",\n",
    "                    line={'color': colors['spatial_median']}),col=col, row=row\n",
    "                )\n",
    "    \n",
    "    \n",
    "    fig.add_trace(go.Scatter(  # add the CAMS analysis concentration data closest to the fireevent\n",
    "                x=df_fire_event['time'],\n",
    "                y=df_fire_event['fire_event'].rolling(window=3, min_periods=1).mean(),\n",
    "                mode='lines',\n",
    "                legendgroup=f\"group_fe\",\n",
    "                name='CAMS Regional Analysis cell closest to fire event',\n",
    "                showlegend=show_legend,\n",
    "                line={'color': colors['fire_event']}),col=col, row=row\n",
    "            )\n",
    "    \n",
    "    \n",
    "    \n",
    "    if file_name is not None:\n",
    "        pass\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def ds_to_pandas(ds, timestamp, lat, long, days, var_name, ident=None):\n",
    "    \n",
    "    if ident=='Aqua':\n",
    "        ds = ds.sel(ident=784)\n",
    "    elif ident=='Terra':\n",
    "        ds = ds.sel(ident=783)\n",
    "    \n",
    "    ds_time = ds.sel(time=slice(\n",
    "            timestamp.replace(minute=0) - timedelta(days=days),\n",
    "            timestamp.replace(minute=0) + timedelta(days=days)\n",
    "        ))\n",
    "    \n",
    "    ds_loc = ds_time.sel(\n",
    "                    latitude=lat,\n",
    "                    longitude=long,\n",
    "                    method='nearest'\n",
    "                )\n",
    "        \n",
    "    df = ds_loc.to_dataframe().reset_index()[['time', var_name]]\n",
    "    \n",
    "    return df, ds_time\n",
    "\n",
    "def _to_datetime(dataset: xr.Dataset):\n",
    "    \"\"\"Convert the time column of newly downloaded CAMS analysis data into datetime objects\"\"\"\n",
    "\n",
    "    # Strip the start date from the ANALYSIS attribute\n",
    "    start_date = datetime.strptime(dataset.FORECAST[:16], 'Europe, %Y%m%d')\n",
    "\n",
    "    def convert_to_datetime(x):  # inner function used to add the timedelta to the start date\n",
    "        return start_date + x\n",
    "\n",
    "    dataset['time'] = dataset.time.to_pandas().apply(convert_to_datetime)  # convert the time parameter to datetime\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FC_LEADTIME > 24:\n",
    "    filename = 'forecast.zip'\n",
    "else:\n",
    "    filename = 'forecast.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66369fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download forecast data from the ADS\n",
    "\n",
    "if FORECAST:\n",
    "    \n",
    "    if not os.path.exists('temp'):\n",
    "        os.makedirs('temp')\n",
    "            \n",
    "    c = cdsapi.Client(\n",
    "        url=ADS_URL,\n",
    "        key=ADS_KEY\n",
    "    )\n",
    "\n",
    "    start = (time_window['start'] - timedelta(days=DAYS)).strftime('%Y-%m-%d')\n",
    "    end = (time_window['end'] + timedelta(days=DAYS)).strftime('%Y-%m-%d')\n",
    "\n",
    "    if FC_LEADTIME > 24:\n",
    "        filename = 'temp/forecast.zip'\n",
    "    else:\n",
    "        filename = 'temp/forecast.nc'\n",
    "\n",
    "    c.retrieve(\n",
    "        'cams-europe-air-quality-forecasts',\n",
    "        {\n",
    "            'variable': ['carbon_monoxide', 'nitrogen_dioxide', 'nitrogen_monoxide',\n",
    "                         'ozone', 'particulate_matter_10um', 'particulate_matter_2.5um',\n",
    "                         'sulphur_dioxide',\n",
    "                        ],\n",
    "            'model': 'ensemble',\n",
    "            'level': '0',\n",
    "            'date': f\"{start}/{end}\",\n",
    "            'type': 'forecast',\n",
    "            'time': '00:00',\n",
    "            'leadtime_hour': [str(hour) for hour in range(0, FC_LEADTIME)],\n",
    "            'area': EXTENTS['IRELAND']['LIST'],\n",
    "            'format': 'netcdf',\n",
    "        },\n",
    "        filename)\n",
    "\n",
    "\n",
    "    if FC_LEADTIME > 24:\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(f'temp/')\n",
    "\n",
    "        forecast_files = glob.glob('temp/*.nc')\n",
    "        forecast_collection = [_to_datetime(xr.open_dataset(x)) for x in forecast_files]\n",
    "    else:\n",
    "        ds_forecast = xr.open_dataset(filename)\n",
    "        ds_forecast = _to_datetime(ds_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FORECAST:\n",
    "    if FC_LEADTIME > 24:\n",
    "\n",
    "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall(f'temp/')\n",
    "\n",
    "            forecast_files = glob.glob('temp/*.nc')\n",
    "            forecast_collection = [_to_datetime(xr.open_dataset(x)) for x in forecast_files]\n",
    "    else:\n",
    "        ds_forecast = xr.open_dataset(filename)\n",
    "        ds_forecast = _to_datetime(ds_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829af820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "if FRP:\n",
    "    ds_frp = xr.open_dataset(Path(DATA_DIR_GFAS).joinpath('frp.nc'))\n",
    "    \n",
    "if PM10_WILDFIRES:\n",
    "    ds_wfpm10 = xr.open_dataset(Path(DATA_DIR_CAMS_AN).joinpath('pmwf_conc.nc'))\n",
    "\n",
    "\n",
    "plot_position = {\n",
    "    0:{'row':1, 'col':1},\n",
    "    1:{'row':1, 'col':2},\n",
    "    2:{'row':1, 'col':3},\n",
    "    3:{'row':2, 'col':1},\n",
    "    4:{'row':2, 'col':2},\n",
    "    5:{'row':2, 'col':3},\n",
    "    6:{'row':3, 'col':1},\n",
    "}\n",
    "    \n",
    "\n",
    "for ind, fe in df_fire_events.iterrows():\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=3,\n",
    "        subplot_titles = [POLLUTANTS[x]['FORMULA_HTML'] for x in POLLUTANTS],\n",
    "        specs=[[{\"secondary_y\": FRP}, {\"secondary_y\": FRP}, {\"secondary_y\": FRP}],\n",
    "               [{\"secondary_y\": FRP}, {\"secondary_y\": FRP}, {\"secondary_y\": FRP}],\n",
    "               [{\"secondary_y\": FRP}, {\"secondary_y\": FRP}, {\"secondary_y\": FRP}],\n",
    "              ]\n",
    "        \n",
    "    )\n",
    "    \n",
    "    for ind, pollutant in enumerate(POLLUTANTS):\n",
    "        \n",
    "        row = plot_position[ind]['row']\n",
    "        col = plot_position[ind]['col']\n",
    "\n",
    "        name_pollutant = POLLUTANTS[pollutant]['FULL_NAME']\n",
    "        name_pollutant_html = POLLUTANTS[pollutant]['FORMULA_HTML']\n",
    "        name_pollutant_var = POLLUTANTS[pollutant]['CAMS']\n",
    "        \n",
    "        \n",
    "        # Update xaxis properties\n",
    "        fig.update_xaxes(title_text=\"Date\",col=col, row=row)\n",
    "\n",
    "        # Update yaxis properties\n",
    "        fig.update_yaxes(title_text=f\"{name_pollutant_html} Concentration (µg m<sup>-3</sup>)\",col=col, row=row)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            ds_an = xr.open_dataset(Path(DATA_DIR_CAMS_AN).joinpath(f'{pollutant}/cams_nrt_analysis_{pollutant}_2018.nc')) \n",
    "                \n",
    "            df_fire_event, ds_fire_event = ds_to_pandas(\n",
    "                ds_an,\n",
    "                fe['datetime'],\n",
    "                fe['latitude'],\n",
    "                fe['longitude'],\n",
    "                DAYS,\n",
    "                name_pollutant_var\n",
    "            )\n",
    "            \n",
    "            df_fire_event = df_fire_event.rename(columns={name_pollutant_var:'fire_event'})\n",
    "            \n",
    "            if SPATIAL_BASELINE_AN:\n",
    "                df_spatial_baseline, ds_fe, _, _ = get_spatial_baseline(\n",
    "                    fe_lat=fe['latitude'],\n",
    "                    fe_long=fe['longitude'],\n",
    "                    timestamp=fe['datetime'],\n",
    "                    days=DAYS,\n",
    "                    pollutant=pollutant,\n",
    "                    meteo_dataset='MERA',\n",
    "                    min_distance_km=50,\n",
    "                    max_distance_km=250,\n",
    "                    number_of_neighbours=50,\n",
    "                    mask_ocean=True,   \n",
    "                )\n",
    "            else:\n",
    "                df_spatial_baseline = None\n",
    "            \n",
    "            if TEMPORAL_BASELINE:\n",
    "                df_temporal_baseline = get_temporal_baseline(\n",
    "                    fe_lat=fe['latitude'],\n",
    "                    fe_long=fe['longitude'],\n",
    "                    timestamp=fe['datetime'],\n",
    "                    days=DAYS,\n",
    "                    pollutant=pollutant,\n",
    "                )\n",
    "            else:\n",
    "                df_temporal_baseline = None\n",
    "            \n",
    "            # Inititate the plotly figure\n",
    "            \n",
    "            if ind == (len(POLLUTANTS) - 1):\n",
    "                leg = True\n",
    "            else:\n",
    "                leg = False\n",
    "            \n",
    "            fig = create_plot(\n",
    "                fig,\n",
    "                col,\n",
    "                row,\n",
    "                name_pollutant,\n",
    "                df_fire_event,\n",
    "                show_legend=leg,\n",
    "                df_temporal=df_temporal_baseline, \n",
    "                df_spatial=df_spatial_baseline,\n",
    "                second_y=FRP\n",
    "            )\n",
    "            \n",
    "            \n",
    "            \n",
    "            if GROUND_STATIONS:\n",
    "                data = get_closest_ground_station_historical_data(\n",
    "                    lat=fe['latitude'],\n",
    "                    long=fe['longitude'],\n",
    "                    timestamp=fe['datetime'],\n",
    "                    pollutant=name_pollutant_var,\n",
    "                    quantity=3\n",
    "                )\n",
    "                \n",
    "                if data is None:\n",
    "                    pass\n",
    "                else:\n",
    "                    for gs in data:\n",
    "                        \n",
    "                        df_gs = data[gs]['data']\n",
    "                        name = data[gs]['name']\n",
    "                        distance  = data[gs]['distance']\n",
    "                        \n",
    "                        if distance > 1000:\n",
    "                            distance = round(distance / 1000)\n",
    "                            trace_name = f'Ground Station ({name}, distance: {distance}KM)'\n",
    "                        else:\n",
    "                            distance = round(distance)\n",
    "                            trace_name = f'Ground Station ({name}, distance: {distance}M)'\n",
    "                        \n",
    "                        fig.add_trace(go.Scatter(  # add the CAMS analysis concentration data closest to the fireevent\n",
    "                            x=df_gs['time'],\n",
    "                            y=df_gs['ground_station_data'].rolling(window=3, min_periods=1).mean(),\n",
    "                            mode='lines',\n",
    "                            name=trace_name,\n",
    "                            legendgroup=trace_name),col=col, row=row\n",
    "                                     )\n",
    "\n",
    "            if REANALYSIS:\n",
    "                \n",
    "                ds_re = xr.open_dataset(Path(DATA_DIR_CAMS_RE).joinpath(f'{pollutant}/cams_reanalysis_{pollutant}_2018.nc'))\n",
    "                \n",
    "                df_re_fe, ds_re_time = ds_to_pandas(\n",
    "                        ds_re,\n",
    "                        fe['datetime'],\n",
    "                        fe['latitude'],\n",
    "                        fe['longitude'],\n",
    "                        DAYS,\n",
    "                        name_pollutant_var\n",
    "                    )\n",
    "                \n",
    "                if ind == (len(POLLUTANTS) - 1):\n",
    "                \n",
    "                    fig.add_trace(go.Scatter(  # add the CAMS analysis concentration data closest to the fireevent\n",
    "                            x=df_re_fe['time'],\n",
    "                            y=df_re_fe[name_pollutant_var].rolling(window=3, min_periods=1).mean(),\n",
    "                            mode='lines',\n",
    "                            name='Reanalysis',\n",
    "                            legendgroup=f\"reanalysis\",\n",
    "                            showlegend=True,\n",
    "                            line={'color': '#1f78b4'}),col=col, row=row\n",
    "                        )\n",
    "                else:\n",
    "                    fig.add_trace(go.Scatter(  # add the CAMS analysis concentration data closest to the fireevent\n",
    "                            x=df_re_fe['time'],\n",
    "                            y=df_re_fe[name_pollutant_var].rolling(window=3, min_periods=1).mean(),\n",
    "                            mode='lines',\n",
    "                            name='Reanalysis',\n",
    "                            showlegend=False,\n",
    "                            legendgroup=f\"reanalysis\",\n",
    "                            line={'color': '#1f78b4'}),col=col, row=row\n",
    "                        )\n",
    "            \n",
    "            if PM10_WILDFIRES:\n",
    "                df_wfpm10_fe, ds_wfpm10_time = ds_to_pandas(\n",
    "                        ds_wfpm10,\n",
    "                        fe['datetime'],\n",
    "                        fe['latitude'],\n",
    "                        fe['longitude'],\n",
    "                        DAYS,\n",
    "                        'pmwf_conc'\n",
    "                    )\n",
    "                \n",
    "                fig.add_trace(go.Scatter(  # add the CAMS analysis concentration data closest to the fireevent\n",
    "                        x=df_wfpm10_fe['time'],\n",
    "                        y=df_wfpm10_fe['pmwf_conc'].rolling(window=3, min_periods=1).mean(),\n",
    "                        mode='lines',\n",
    "                        name='Wildfire PM10',\n",
    "                        legendgroup=f\"group_wf\",\n",
    "                        line={'color': 'orange'}),col=col, row=row\n",
    "                    )\n",
    "\n",
    "            \n",
    "            if FRP:\n",
    "                df_frp_fe, ds_frp_time = ds_to_pandas(\n",
    "                    ds_frp,\n",
    "                    fe['datetime'],\n",
    "                    fe['latitude'],\n",
    "                    fe['longitude'],\n",
    "                    DAYS,\n",
    "                    'frpfire',\n",
    "                    ident=fe['reference']\n",
    "                )\n",
    "                \n",
    "                fig.update_yaxes(title_text=f\"FRP\", secondary_y=True, col=col, row=row)\n",
    "                \n",
    "                max_frp = df_frp_fe['frpfire'].max()\n",
    "\n",
    "                if max_frp == 0:\n",
    "                    max_frp = 1\n",
    "                \n",
    "                fig.update_yaxes(range=[0, max_frp], secondary_y=True,)\n",
    "                \n",
    "                if ind == (len(POLLUTANTS) - 1):\n",
    "                \n",
    "                    fig.add_trace(go.Scatter(  # add the CAMS analysis concentration data closest to the fireevent\n",
    "                            x=df_frp_fe['time'],\n",
    "                            y=df_frp_fe['frpfire'].rolling(window=3, min_periods=1).mean(),\n",
    "                            mode='lines',\n",
    "                            name='FRP',\n",
    "                            showlegend=True,\n",
    "                            legendgroup=f\"group_frp\",\n",
    "                            line={'color': '#ff7f00'}),\n",
    "                            col=col,\n",
    "                            row=row,\n",
    "                            secondary_y=True,\n",
    "                        )\n",
    "                else:\n",
    "                \n",
    "                    fig.add_trace(go.Scatter(  # add the CAMS analysis concentration data closest to the fireevent\n",
    "                            x=df_frp_fe['time'],\n",
    "                            y=df_frp_fe['frpfire'].rolling(window=3, min_periods=1).mean(),\n",
    "                            mode='lines',\n",
    "                            name='FRP',\n",
    "                            showlegend=False,\n",
    "                            legendgroup=f\"group_frp\",\n",
    "                            line={'color': '#ff7f00'}),\n",
    "                            col=col,\n",
    "                            row=row,\n",
    "                            secondary_y=True,\n",
    "                                 )\n",
    "            \n",
    "            if FORECAST:\n",
    "                if FC_LEADTIME > 24:\n",
    "                    for ind, fc_file in enumerate(forecast_collection):\n",
    "                        df_fc_fe, df_fc_time = ds_to_pandas(\n",
    "                            fc_file,\n",
    "                            fe['datetime'],\n",
    "                            fe['latitude'],\n",
    "                            fe['longitude'],\n",
    "                            DAYS,\n",
    "                            name_pollutant_var\n",
    "                        )\n",
    "\n",
    "                        start_date = datetime.strptime(fc_file.FORECAST[:16], 'Europe, %Y%m%d')\n",
    "\n",
    "                        fig.add_trace(go.Scatter(  # add the CAMS analysis concentration data closest to the fireevent\n",
    "                            x=df_fc_fe['time'],\n",
    "                            y=df_fc_fe[name_pollutant_var],\n",
    "                            mode='lines',\n",
    "                            legendgroup=f\"group_{ind}\",\n",
    "                            name=f'Forecast {start_date.strftime(\"%d %B\")}'),col=col, row=row                              \n",
    "                        )\n",
    "                else:\n",
    "\n",
    "                    df_fc_fe, df_fc_time = ds_to_pandas(\n",
    "                        ds_forecast,\n",
    "                        fe['datetime'],\n",
    "                        fe['latitude'],\n",
    "                        fe['longitude'],\n",
    "                        DAYS,\n",
    "                        name_pollutant_var\n",
    "                    )\n",
    "\n",
    "                    fig.add_trace(go.Scatter(  # add the CAMS analysis concentration data closest to the fireevent\n",
    "                        x=df_fc_fe['time'],\n",
    "                        y=df_fc_fe[name_pollutant_var],\n",
    "                        mode='lines',\n",
    "                        name='Forecast',\n",
    "                        legendgroup=f\"group_1\",\n",
    "                        line={'color': 'pink'}),col=col, row=row\n",
    "                    )\n",
    "            \n",
    "            fig.add_vline(x=fe['datetime'], line_width=3, line_dash=\"dash\", line_color=\"orange\", col=col, row=row)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            raise\n",
    "            print(f'Skipping fire {ind} because of the following error: {e}')\n",
    "    \n",
    "    fig.update_layout( legend=dict(  # position the legend\n",
    "        yanchor=\"top\",\n",
    "        y=-0.2,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01,\n",
    "        orientation=\"h\"\n",
    "    )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(legend=dict(font = dict(size = 25, color = \"black\")))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        template=pio.templates[\"seaborn\"],\n",
    "        autosize=False,\n",
    "        width=1000,\n",
    "        height=500\n",
    "    )  \n",
    "    \n",
    "    fig.update_layout( legend=dict(  # position the legend\n",
    "        yanchor=\"top\",\n",
    "        y=-0.2,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1600,\n",
    "        height=900,\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=100,\n",
    "            t=100,\n",
    "            pad=4\n",
    "        ),\n",
    "        )\n",
    "    fig.show()\n",
    "    \n",
    "    output_loc_fig = Path(DATA_DIR_PLOTS).joinpath('notebooks/analysis_vs_reanalysis/plot/')\n",
    "    \n",
    "    if not os.path.exists(output_loc_fig):\n",
    "        os.makedirs(output_loc_fig)\n",
    "        \n",
    "    fig.write_html(output_loc_fig.joinpath(f\"analysis_vs_reanalysis_{fe['id']}_{fe['datetime'].strftime('%m_%d_%Y')}.html\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
